{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.7.4.5-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting bleach (from kaggle)\n",
      "  Downloading bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages (from kaggle) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer in /opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages (from kaggle) (3.3.2)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages (from kaggle) (3.7)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages (from kaggle) (4.25.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages (from kaggle) (2.9.0.post0)\n",
      "Collecting python-slugify (from kaggle)\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages (from kaggle) (2.31.0)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages (from kaggle) (68.2.2)\n",
      "Requirement already satisfied: six>=1.10 in /opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages (from kaggle) (1.16.0)\n",
      "Collecting text-unidecode (from kaggle)\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages (from kaggle) (4.66.2)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /opt/anaconda3/envs/nlp_workshop/lib/python3.9/site-packages (from kaggle) (2.2.1)\n",
      "Collecting webencodings (from kaggle)\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Downloading kaggle-1.7.4.5-py3-none-any.whl (181 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m181.2/181.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading bleach-6.2.0-py3-none-any.whl (163 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m163.4/163.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: webencodings, text-unidecode, python-slugify, bleach, kaggle\n",
      "Successfully installed bleach-6.2.0 kaggle-1.7.4.5 python-slugify-8.0.4 text-unidecode-1.3 webencodings-0.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To access Kaggle datasets, you must authenticate using a Kaggle API token.\n",
    "# Download your 'kaggle.json' from your Kaggle account settings and provide its path below.\n",
    "kaggle_json_path = \"kaggle-2.json\"\n",
    "\n",
    "\n",
    "dataset_name = \"us-election-2020-tweets\"\n",
    "dataset_url = \"https://www.kaggle.com/datasets/manchunhui/us-election-2020-tweets\"\n",
    "download_dir = \"./data\" # in regular Databricks env we could write to our workspace or other DFS path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zalogowano do Kaggle jako: cezarykumowicz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "kaggle_json_path = \"kaggle-2.json\"  # plik w tym samym folderze co notebook\n",
    "\n",
    "# 1. Wczytaj credentials z pliku\n",
    "with open(kaggle_json_path, \"r\") as f:\n",
    "    kaggle_creds = json.load(f)\n",
    "\n",
    "os.environ[\"KAGGLE_USERNAME\"] = kaggle_creds[\"username\"]\n",
    "os.environ[\"KAGGLE_KEY\"] = kaggle_creds[\"key\"]\n",
    "\n",
    "# 2. Dopiero TERAZ importuj KaggleApi\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "# 3. Autoryzacja\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "print(\"Zalogowano do Kaggle jako:\", kaggle_creds[\"username\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/manchunhui/us-election-2020-tweets\n",
      "Pobrano i rozpakowano dataset do: ./data\n"
     ]
    }
   ],
   "source": [
    "# slug datasetu na Kaggle\n",
    "dataset_slug = f\"manchunhui/{dataset_name}\"\n",
    "\n",
    "# upewnij siƒô, ≈ºe katalog istnieje\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "# pobieramy i rozpakowujemy pliki\n",
    "api.dataset_download_files(\n",
    "    dataset=dataset_slug,\n",
    "    path=download_dir,\n",
    "    unzip=True\n",
    ")\n",
    "\n",
    "print(f\"Pobrano i rozpakowano dataset do: {download_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              created_at                tweet_id  \\\n",
      "0    2020-10-15 00:00:01   1.316529221557252e+18   \n",
      "1    2020-10-15 00:00:01  1.3165292227484303e+18   \n",
      "2    2020-10-15 00:00:02   1.316529228091847e+18   \n",
      "3    2020-10-15 00:00:02   1.316529227471237e+18   \n",
      "4    2020-10-15 00:00:08  1.3165292523014513e+18   \n",
      "..                   ...                     ...   \n",
      "495  2020-10-15 00:28:07   1.316536295129264e+18   \n",
      "496  2020-10-15 00:28:21   1.316536354541654e+18   \n",
      "497  2020-10-15 00:28:23  1.3165363610636452e+18   \n",
      "498  2020-10-15 00:28:24  1.3165363680219996e+18   \n",
      "499  2020-10-15 00:28:26   1.316536374452007e+18   \n",
      "\n",
      "                                                 tweet likes  retweet_count  \\\n",
      "0    #Elecciones2020 | En #Florida: #JoeBiden dice ...   0.0            0.0   \n",
      "1    Usa 2020, Trump contro Facebook e Twitter: cop...  26.0            9.0   \n",
      "2    #Trump: As a student I used to hear for years,...   2.0            1.0   \n",
      "3    2 hours since last tweet from #Trump! Maybe he...   0.0            0.0   \n",
      "4    You get a tie! And you get a tie! #Trump ‚Äòs ra...   4.0            3.0   \n",
      "..                                                 ...   ...            ...   \n",
      "495  ‚ÄúAll that shit I didn‚Äôt try to do for the firs...   0.0            0.0   \n",
      "496  Pretty certain Laura Branigan is turning in he...   0.0            0.0   \n",
      "497  #Trump: Do we have time for one quick story--\\...   0.0            1.0   \n",
      "498           @funder #Trump #TrumpsTheBiggestLiarEver   0.0            0.0   \n",
      "499  BREAKING NEWS: The ‚ÄúYuuge‚Äù treasonous spying o...   4.0            1.0   \n",
      "\n",
      "                 source               user_id              user_name  \\\n",
      "0             TweetDeck           360666534.0     El Sol Latino News   \n",
      "1      Social Mediaset            331617619.0                Tgcom24   \n",
      "2       Twitter Web App             8436472.0                 snarke   \n",
      "3         Trumpytweeter  8.28355589206057e+17          Trumpytweeter   \n",
      "4    Twitter for iPhone            47413798.0  Rana Abtar - ÿ±ŸÜÿß ÿ£ÿ®ÿ™ÿ±   \n",
      "..                  ...                   ...                    ...   \n",
      "495  Twitter for iPhone            16119126.0               DK DeKay   \n",
      "496  Twitter for iPhone           485744590.0                  James   \n",
      "497     Twitter Web App             8436472.0                 snarke   \n",
      "498  Twitter for iPhone           402199039.0            debbie gore   \n",
      "499  Twitter for iPhone           130517690.0     Morris Dalla Costa   \n",
      "\n",
      "    user_screen_name                                   user_description  ...  \\\n",
      "0    elsollatinonews  üåê Noticias de inter√©s para latinos de la costa...  ...   \n",
      "1    MediasetTgcom24  Profilo ufficiale di Tgcom24: tutte le notizie...  ...   \n",
      "2             snarke  Will mock for food! Freelance writer, blogger,...  ...   \n",
      "3      trumpytweeter  If he doesn't tweet for some time, should we b...  ...   \n",
      "4          Ranaabtar  Washington Correspondent, Lebanese-American ,c...  ...   \n",
      "..               ...                                                ...  ...   \n",
      "495    HairlessComic  (he/him) I‚Äôm the Michael Jordan of not living ...  ...   \n",
      "496           joon0u        Be the change you wish to see in the world.  ...   \n",
      "497           snarke  Will mock for food! Freelance writer, blogger,...  ...   \n",
      "498      debbie_gore                                                NaN  ...   \n",
      "499     MorrisDCosta  Morris Dalla Costa, writer, columnist at large...  ...   \n",
      "\n",
      "    user_followers_count                 user_location         lat  \\\n",
      "0                 1860.0  Philadelphia, PA / Miami, FL    25.77427   \n",
      "1              1067661.0                           NaN         NaN   \n",
      "2                 1185.0                      Portland  45.5202471   \n",
      "3                   32.0                           NaN         NaN   \n",
      "4                 5393.0                 Washington DC  38.8949924   \n",
      "..                   ...                           ...         ...   \n",
      "495                317.0                       Vermont  44.5990718   \n",
      "496                 88.0                           NYC  40.7127281   \n",
      "497               1185.0                      Portland  45.5202471   \n",
      "498                 12.0                           NaN         NaN   \n",
      "499               4192.0                    London, ON  51.5073219   \n",
      "\n",
      "             long        city                   country      continent  \\\n",
      "0       -80.19366         NaN  United States of America  North America   \n",
      "1             NaN         NaN                       NaN            NaN   \n",
      "2    -122.6741949    Portland  United States of America  North America   \n",
      "3             NaN         NaN                       NaN            NaN   \n",
      "4     -77.0365581  Washington  United States of America  North America   \n",
      "..            ...         ...                       ...            ...   \n",
      "495   -72.5002608         NaN  United States of America  North America   \n",
      "496   -74.0060152    New York  United States of America  North America   \n",
      "497  -122.6741949    Portland  United States of America  North America   \n",
      "498           NaN         NaN                       NaN            NaN   \n",
      "499    -0.1276474      London            United Kingdom         Europe   \n",
      "\n",
      "                    state state_code                   collected_at  \n",
      "0                 Florida         FL            2020-10-21 00:00:00  \n",
      "1                     NaN        NaN  2020-10-21 00:00:00.373216530  \n",
      "2                  Oregon         OR  2020-10-21 00:00:00.746433060  \n",
      "3                     NaN        NaN  2020-10-21 00:00:01.119649591  \n",
      "4    District of Columbia         DC  2020-10-21 00:00:01.492866121  \n",
      "..                    ...        ...                            ...  \n",
      "495               Vermont         VT  2020-10-21 00:03:06.608265191  \n",
      "496              New York         NY  2020-10-21 00:03:06.981481721  \n",
      "497                Oregon         OR  2020-10-21 00:03:07.354698251  \n",
      "498                   NaN        NaN  2020-10-21 00:03:07.727914782  \n",
      "499               England        ENG  2020-10-21 00:03:08.101131312  \n",
      "\n",
      "[500 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "trump = pd.read_csv(\"data/hashtag_donaldtrump.csv\", engine='python')\n",
    "\n",
    "trump_short = trump.head(500)\n",
    "print(trump_short)\n",
    "\n",
    "trump_short.to_csv(\"data/trump_short.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_workshop",
   "language": "python",
   "name": "nlp_workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
