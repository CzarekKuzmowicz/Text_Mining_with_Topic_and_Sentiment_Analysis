{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We separate language filtering into a dedicated notebook because the dataset is large and multilingual. A fast language identification model is used to detect the language of each tweet efficiently. We keep only English tweets to ensure consistent topic modelling and sentiment analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies with `uv` (see README), then restart the kernel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import urllib.request\n",
    "import fasttext\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file  = \"data/hashtag_donaldtrump.csv\"\n",
    "output_file = \"data/hashtag_donaldtrump_en.csv\"\n",
    "\n",
    "model_file = \"lid.176.ftz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model already exists: lid.176.ftz\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(model_file):\n",
    "    url = \"https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.ftz\"\n",
    "    print(\"Downloading model...\")\n",
    "    urllib.request.urlretrieve(url, model_file)\n",
    "    print(\"Done:\", model_file)\n",
    "else:\n",
    "    print(\"Model already exists:\", model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.load_model(model_file)\n",
    "\n",
    "def clean_for_lang(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r\"http\\S+|www\\.\\S+\", \" \", text)  # remove URLs\n",
    "    text = re.sub(r\"@\\w+\", \" \", text)             # remove @mentions\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()      # normalize spaces\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 49994 | Kept English: 34670\n",
      "Processed: 99987 | Kept English: 69279\n",
      "Processed: 149980 | Kept English: 103154\n",
      "Processed: 199979 | Kept English: 137062\n",
      "Processed: 249973 | Kept English: 170684\n",
      "Processed: 299963 | Kept English: 203599\n",
      "Processed: 349957 | Kept English: 237743\n",
      "Processed: 399952 | Kept English: 270128\n",
      "Processed: 449949 | Kept English: 300111\n",
      "Processed: 499945 | Kept English: 326793\n",
      "Processed: 549945 | Kept English: 346952\n",
      "Processed: 599944 | Kept English: 364312\n",
      "Processed: 649943 | Kept English: 385126\n",
      "Processed: 699940 | Kept English: 408850\n",
      "Processed: 749940 | Kept English: 436230\n",
      "Processed: 799937 | Kept English: 459331\n",
      "Processed: 849935 | Kept English: 485285\n",
      "Processed: 899935 | Kept English: 506889\n",
      "Processed: 949930 | Kept English: 531346\n",
      "Processed: 971087 | Kept English: 542322\n",
      "\n",
      "DONE. Saved English tweets to: data/hashtag_donaldtrump_en.csv\n"
     ]
    }
   ],
   "source": [
    "for chunk in pd.read_csv(\n",
    "    input_file,\n",
    "    chunksize=chunksize,\n",
    "    engine=\"python\",\n",
    "    on_bad_lines=\"skip\"\n",
    "):\n",
    "    total += len(chunk)\n",
    "\n",
    "    # make sure tweet column exists and is not empty\n",
    "    if \"tweet\" not in chunk.columns:\n",
    "        raise ValueError(\"No 'tweet' column found in this file.\")\n",
    "\n",
    "    chunk = chunk.dropna(subset=[\"tweet\"])\n",
    "\n",
    "    texts = chunk[\"tweet\"].apply(clean_for_lang).tolist()\n",
    "    labels, probs = model.predict(texts, k=1)\n",
    "\n",
    "    chunk[\"lang_pred\"] = [x[0].replace(\"__label__\", \"\") for x in labels]\n",
    "    chunk[\"lang_prob\"] = [x[0] for x in probs]\n",
    "\n",
    "    chunk_en = chunk[(chunk[\"lang_pred\"] == \"en\") & (chunk[\"lang_prob\"] >= confidence)]\n",
    "    kept += len(chunk_en)\n",
    "\n",
    "    chunk_en.to_csv(output_file, mode=\"w\" if first else \"a\", index=False, header=first)\n",
    "    first = False\n",
    "\n",
    "    print(\"Processed:\", total, \"| Kept English:\", kept)\n",
    "\n",
    "print(\"\\nDONE. Saved English tweets to:\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>lang_pred</th>\n",
       "      <th>lang_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-10-15 00:00:02</td>\n",
       "      <td>1.316529e+18</td>\n",
       "      <td>#Trump: As a student I used to hear for years,...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.993831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-15 00:00:02</td>\n",
       "      <td>1.316529e+18</td>\n",
       "      <td>2 hours since last tweet from #Trump! Maybe he...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.975893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-10-15 00:00:17</td>\n",
       "      <td>1.316529e+18</td>\n",
       "      <td>@CLady62 Her 15 minutes were over long time ag...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.981575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-10-15 00:00:17</td>\n",
       "      <td>1.316529e+18</td>\n",
       "      <td>@richardmarx Glad u got out of the house! DICK...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.924819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-10-15 00:00:18</td>\n",
       "      <td>1.316529e+18</td>\n",
       "      <td>@DeeviousDenise @realDonaldTrump @nypost There...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.980735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            created_at      tweet_id  \\\n",
       "0  2020-10-15 00:00:02  1.316529e+18   \n",
       "1  2020-10-15 00:00:02  1.316529e+18   \n",
       "2  2020-10-15 00:00:17  1.316529e+18   \n",
       "3  2020-10-15 00:00:17  1.316529e+18   \n",
       "4  2020-10-15 00:00:18  1.316529e+18   \n",
       "\n",
       "                                               tweet lang_pred  lang_prob  \n",
       "0  #Trump: As a student I used to hear for years,...        en   0.993831  \n",
       "1  2 hours since last tweet from #Trump! Maybe he...        en   0.975893  \n",
       "2  @CLady62 Her 15 minutes were over long time ag...        en   0.981575  \n",
       "3  @richardmarx Glad u got out of the house! DICK...        en   0.924819  \n",
       "4  @DeeviousDenise @realDonaldTrump @nypost There...        en   0.980735  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_en = pd.read_csv(output_file, nrows=5, low_memory=False)\n",
    "df_en[[\"created_at\", \"tweet_id\", \"tweet\", \"lang_pred\", \"lang_prob\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_workshop",
   "language": "python",
   "name": "nlp_workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}